{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:38.980185Z",
     "start_time": "2024-04-15T13:45:38.966059Z"
    }
   },
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:39.547175Z",
     "start_time": "2024-04-15T13:45:39.379824Z"
    }
   },
   "source": [
    "lines=pd.read_csv(\"./data/spa.txt\", delimiter=\"\\t\", encoding='utf-8', \n",
    "                  names = ['english','spanish'], header=None)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:39.837233Z",
     "start_time": "2024-04-15T13:45:39.824880Z"
    }
   },
   "source": "lines",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  english                                            spanish\n",
       "0                                                     Go.                                                Ve.\n",
       "1                                                     Go.                                              Vete.\n",
       "2                                                     Go.                                              Vaya.\n",
       "3                                                     Go.                                            Váyase.\n",
       "4                                                     Hi.                                              Hola.\n",
       "...                                                   ...                                                ...\n",
       "141538  A carbon footprint is the amount of carbon dio...  Una huella de carbono es la cantidad de contam...\n",
       "141539  Since there are usually multiple websites on a...  Como suele haber varias páginas web sobre cual...\n",
       "141540  If you want to sound like a native speaker, yo...  Si quieres sonar como un hablante nativo, debe...\n",
       "141541  It may be impossible to get a completely error...  Puede que sea imposible obtener un corpus comp...\n",
       "141542  One day, I woke up to find that God had put ha...  Un día, me desperté y vi que Dios me había pue...\n",
       "\n",
       "[141543 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141538</th>\n",
       "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
       "      <td>Una huella de carbono es la cantidad de contam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141539</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Como suele haber varias páginas web sobre cual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141540</th>\n",
       "      <td>If you want to sound like a native speaker, yo...</td>\n",
       "      <td>Si quieres sonar como un hablante nativo, debe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141541</th>\n",
       "      <td>It may be impossible to get a completely error...</td>\n",
       "      <td>Puede que sea imposible obtener un corpus comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141542</th>\n",
       "      <td>One day, I woke up to find that God had put ha...</td>\n",
       "      <td>Un día, me desperté y vi que Dios me había pue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141543 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:40.558408Z",
     "start_time": "2024-04-15T13:45:40.548554Z"
    }
   },
   "source": [
    "pd.isnull(lines).sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english    0\n",
       "spanish    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:41.253877Z",
     "start_time": "2024-04-15T13:45:41.243099Z"
    }
   },
   "source": "lines=lines[~pd.isnull(lines['english'])]",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:41.808723Z",
     "start_time": "2024-04-15T13:45:41.757350Z"
    }
   },
   "source": [
    "lines.drop_duplicates(inplace=True)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:42.525591Z",
     "start_time": "2024-04-15T13:45:42.515081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Let us pick any 25000 rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:43.795206Z",
     "start_time": "2024-04-15T13:45:43.792727Z"
    }
   },
   "source": "lines.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:44.272496Z",
     "start_time": "2024-04-15T13:45:44.252215Z"
    }
   },
   "source": [
    "# Lowercase all characters\n",
    "lines['english']=lines['english'].apply(lambda x: x.lower())\n",
    "lines['spanish']=lines['spanish'].apply(lambda x: x.lower())"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:44.634345Z",
     "start_time": "2024-04-15T13:45:44.613746Z"
    }
   },
   "source": [
    "# Remove quotes\n",
    "lines['english']=lines['english'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['spanish']=lines['spanish'].apply(lambda x: re.sub(\"'\", '', x))"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:44.967554Z",
     "start_time": "2024-04-15T13:45:44.887072Z"
    }
   },
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english']=lines['english'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['spanish']=lines['spanish'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:45.263851Z",
     "start_time": "2024-04-15T13:45:45.156075Z"
    }
   },
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english']=lines['english'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['spanish']=lines['spanish'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english']=lines['english'].apply(lambda x: x.strip())\n",
    "lines['spanish']=lines['spanish'].apply(lambda x: x.strip())\n",
    "lines['english']=lines['english'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['spanish']=lines['spanish'].apply(lambda x: re.sub(\" +\", \" \", x))\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:45.375296Z",
     "start_time": "2024-04-15T13:45:45.369213Z"
    }
   },
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines['spanish'] = lines['spanish'].apply(lambda x : 'START_ '+ x + ' _END')"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:45.576584Z",
     "start_time": "2024-04-15T13:45:45.572379Z"
    }
   },
   "source": [
    "lines.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  english                                            spanish\n",
       "138916  do you remember the day when we met each other...  START_ ¿recuerdas el día en que nos encontramo...\n",
       "80065                      it would be good if you ate it           START_ sería bueno que lo comierais _END\n",
       "132496  tom doesnt like women who wear way too much ma...  START_ a tom no le gustan las mujeres que usan...\n",
       "65965                         our water heater is leaking         START_ nuestro calentador pierde agua _END\n",
       "38472                               dont be irresponsible                  START_ no seas irresponsable _END"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138916</th>\n",
       "      <td>do you remember the day when we met each other...</td>\n",
       "      <td>START_ ¿recuerdas el día en que nos encontramo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80065</th>\n",
       "      <td>it would be good if you ate it</td>\n",
       "      <td>START_ sería bueno que lo comierais _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132496</th>\n",
       "      <td>tom doesnt like women who wear way too much ma...</td>\n",
       "      <td>START_ a tom no le gustan las mujeres que usan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65965</th>\n",
       "      <td>our water heater is leaking</td>\n",
       "      <td>START_ nuestro calentador pierde agua _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38472</th>\n",
       "      <td>dont be irresponsible</td>\n",
       "      <td>START_ no seas irresponsable _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:45.819528Z",
     "start_time": "2024-04-15T13:45:45.779876Z"
    }
   },
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_spanish_words=set()\n",
    "for hin in lines['spanish']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_spanish_words:\n",
    "            all_spanish_words.add(word)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:45.989975Z",
     "start_time": "2024-04-15T13:45:45.983574Z"
    }
   },
   "source": [
    "len(all_eng_words)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7456"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:46.185951Z",
     "start_time": "2024-04-15T13:45:46.183019Z"
    }
   },
   "source": "len(all_spanish_words)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12968"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:46.401506Z",
     "start_time": "2024-04-15T13:45:46.375635Z"
    }
   },
   "source": [
    "lines['length_eng_sentence']=lines['english'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_spa_sentence']=lines['spanish'].apply(lambda x:len(x.split(\" \")))"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:46.585635Z",
     "start_time": "2024-04-15T13:45:46.581239Z"
    }
   },
   "source": [
    "lines.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  english                                            spanish  length_eng_sentence  length_spa_sentence\n",
       "138916  do you remember the day when we met each other...  START_ ¿recuerdas el día en que nos encontramo...                   14                   12\n",
       "80065                      it would be good if you ate it           START_ sería bueno que lo comierais _END                    8                    7\n",
       "132496  tom doesnt like women who wear way too much ma...  START_ a tom no le gustan las mujeres que usan...                   10                   13\n",
       "65965                         our water heater is leaking         START_ nuestro calentador pierde agua _END                    5                    6\n",
       "38472                               dont be irresponsible                  START_ no seas irresponsable _END                    3                    5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_spa_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138916</th>\n",
       "      <td>do you remember the day when we met each other...</td>\n",
       "      <td>START_ ¿recuerdas el día en que nos encontramo...</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80065</th>\n",
       "      <td>it would be good if you ate it</td>\n",
       "      <td>START_ sería bueno que lo comierais _END</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132496</th>\n",
       "      <td>tom doesnt like women who wear way too much ma...</td>\n",
       "      <td>START_ a tom no le gustan las mujeres que usan...</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65965</th>\n",
       "      <td>our water heater is leaking</td>\n",
       "      <td>START_ nuestro calentador pierde agua _END</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38472</th>\n",
       "      <td>dont be irresponsible</td>\n",
       "      <td>START_ no seas irresponsable _END</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:46.819141Z",
     "start_time": "2024-04-15T13:45:46.815871Z"
    }
   },
   "source": [
    "lines[lines['length_eng_sentence']>30].shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:47.047154Z",
     "start_time": "2024-04-15T13:45:47.041720Z"
    }
   },
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_spa_sentence']<=20]"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:47.276589Z",
     "start_time": "2024-04-15T13:45:47.272750Z"
    }
   },
   "source": [
    "lines.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24936, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:47.520212Z",
     "start_time": "2024-04-15T13:45:47.515354Z"
    }
   },
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(lines['length_spa_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:47.734155Z",
     "start_time": "2024-04-15T13:45:47.730152Z"
    }
   },
   "source": [
    "max_length_src=max(lines['length_spa_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:48.011008Z",
     "start_time": "2024-04-15T13:45:48.001894Z"
    }
   },
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_spanish_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_spanish_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7456, 12968)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:48.204712Z",
     "start_time": "2024-04-15T13:45:48.202858Z"
    }
   },
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:48.757088Z",
     "start_time": "2024-04-15T13:45:48.752138Z"
    }
   },
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:49.088738Z",
     "start_time": "2024-04-15T13:45:49.083739Z"
    }
   },
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:49.295549Z",
     "start_time": "2024-04-15T13:45:49.288521Z"
    }
   },
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             english                                            spanish  length_eng_sentence  length_spa_sentence\n",
       "33213                            youre being watched            START_ usted está siendo observado _END                    3                    6\n",
       "16604                              i always screw up                        START_ siempre fracaso _END                    4                    4\n",
       "2820                                      thats over                               START_ se acabó _END                    2                    4\n",
       "68449                   are you going to buy the car                START_ ¿vas a comprar el coche _END                    7                    7\n",
       "101249           their plan sounds interesting to me          START_ su plan me parece interesante _END                    6                    7\n",
       "98335             tom made some mistakes on the test  START_ tom cometió algunos errores en la prueb...                    7                    9\n",
       "29787                           i intend to go there                         START_ pienso ir allí _END                    5                    5\n",
       "73911                  he often comes late to school        START_ a menudo llega tarde al colegio _END                    6                    8\n",
       "122631  how many eggs were you able to get yesterday  START_ ¿cuántos huevos pudiste conseguir ayer ...                    9                    7\n",
       "5828                                    im tired now                    START_ ahora estoy cansado _END                    3                    5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_spa_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33213</th>\n",
       "      <td>youre being watched</td>\n",
       "      <td>START_ usted está siendo observado _END</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16604</th>\n",
       "      <td>i always screw up</td>\n",
       "      <td>START_ siempre fracaso _END</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>thats over</td>\n",
       "      <td>START_ se acabó _END</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68449</th>\n",
       "      <td>are you going to buy the car</td>\n",
       "      <td>START_ ¿vas a comprar el coche _END</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101249</th>\n",
       "      <td>their plan sounds interesting to me</td>\n",
       "      <td>START_ su plan me parece interesante _END</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98335</th>\n",
       "      <td>tom made some mistakes on the test</td>\n",
       "      <td>START_ tom cometió algunos errores en la prueb...</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29787</th>\n",
       "      <td>i intend to go there</td>\n",
       "      <td>START_ pienso ir allí _END</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73911</th>\n",
       "      <td>he often comes late to school</td>\n",
       "      <td>START_ a menudo llega tarde al colegio _END</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122631</th>\n",
       "      <td>how many eggs were you able to get yesterday</td>\n",
       "      <td>START_ ¿cuántos huevos pudiste conseguir ayer ...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5828</th>\n",
       "      <td>im tired now</td>\n",
       "      <td>START_ ahora estoy cansado _END</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:49.748732Z",
     "start_time": "2024-04-15T13:45:49.743680Z"
    }
   },
   "source": [
    "X, y = lines['english'], lines['spanish']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19948,), (4988,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us save this data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:50.227221Z",
     "start_time": "2024-04-15T13:45:50.217972Z"
    }
   },
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')\n"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:50.440531Z",
     "start_time": "2024-04-15T13:45:50.437246Z"
    }
   },
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            return [encoder_input_data, decoder_input_data],decoder_target_data"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:51.057824Z",
     "start_time": "2024-04-15T13:45:50.620227Z"
    }
   },
   "cell_type": "code",
   "source": "x_tr, y_tr = generate_batch(X_train, y_train, batch_size=len(X_train))",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:51.184066Z",
     "start_time": "2024-04-15T13:45:51.059104Z"
    }
   },
   "cell_type": "code",
   "source": "x_ts, y_ts = generate_batch(X_test, y_test, batch_size=len(X_test))\n",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:58.087968Z",
     "start_time": "2024-04-15T13:45:58.080134Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:58.897143Z",
     "start_time": "2024-04-15T13:45:58.894176Z"
    }
   },
   "source": [
    "latent_dim=300"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:59.566818Z",
     "start_time": "2024-04-15T13:45:59.366194Z"
    }
   },
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:45:59.781423Z",
     "start_time": "2024-04-15T13:45:59.690749Z"
    }
   },
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:46:00.090681Z",
     "start_time": "2024-04-15T13:46:00.080946Z"
    }
   },
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:46:00.482457Z",
     "start_time": "2024-04-15T13:46:00.463700Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m) │  \u001B[38;5;34m2,236,800\u001B[0m │ input_layer[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ input_layer[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "│ (\u001B[38;5;33mNotEqual\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m) │  \u001B[38;5;34m3,890,700\u001B[0m │ input_layer_1[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)         │ [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m),     │    \u001B[38;5;34m721,200\u001B[0m │ embedding[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m),      │            │ not_equal[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)       │ [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m,     │    \u001B[38;5;34m721,200\u001B[0m │ embedding_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m… │\n",
       "│                     │ \u001B[38;5;34m300\u001B[0m), (\u001B[38;5;45mNone\u001B[0m,      │            │ lstm[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m1\u001B[0m],       │\n",
       "│                     │ \u001B[38;5;34m300\u001B[0m), (\u001B[38;5;45mNone\u001B[0m,      │            │ lstm[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m2\u001B[0m]        │\n",
       "│                     │ \u001B[38;5;34m300\u001B[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m,      │  \u001B[38;5;34m3,903,669\u001B[0m │ lstm_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "│                     │ \u001B[38;5;34m12969\u001B[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,236,800</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,890,700</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,903,669</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12969</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m11,473,569\u001B[0m (43.77 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,473,569</span> (43.77 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m11,473,569\u001B[0m (43.77 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,473,569</span> (43.77 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:46:01.223457Z",
     "start_time": "2024-04-15T13:46:01.220844Z"
    }
   },
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T13:46:03.681020Z",
     "start_time": "2024-04-15T13:46:03.669223Z"
    }
   },
   "cell_type": "code",
   "source": "X_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19447                          wood burns easily\n",
       "8676                              this is a desk\n",
       "84314             i wont go down without a fight\n",
       "110334    the exercises are simple and effective\n",
       "13505                           i painted my car\n",
       "                           ...                  \n",
       "15258                           wait for me here\n",
       "14515                           swimming is easy\n",
       "20153                         go down the stairs\n",
       "103831       jealous people die but not jealousy\n",
       "68720               do you want to work with tom\n",
       "Name: english, Length: 19948, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-15T13:46:20.049932Z"
    }
   },
   "source": [
    "\"\"\"model.fit(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)\"\"\"\n",
    "model.fit(x=x_tr, y=y_tr,\n",
    "                    steps_per_epoch = train_samples,\n",
    "                    epochs=epochs)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: in order to understand whether this is true\n",
      "Actual Hindi Translation:  यह समझने के लिए कि क्या यह सच है \n",
      "Predicted Hindi Translation:  यह समझने के लिए कि क्या यह सच है \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: to why india is today growing\n",
      "Actual Hindi Translation:  कि भारत आज आगे बढ़ रहा है \n",
      "Predicted Hindi Translation:  कि भारत आज आगे बढ़ रहा है \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: then theyll live years longer”\n",
      "Actual Hindi Translation:  तो वे साल अधिक जियेंगे” \n",
      "Predicted Hindi Translation:  तो वे साल अधिक जियेंगे” \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: and start thinking about the long long line from b to e\n",
      "Actual Hindi Translation:  और सोचना होता है उस लम्बी लम्बी रेखा के बारे में जो बी से ई तक जाती है \n",
      "Predicted Hindi Translation:  और सोचना होता है और पता चला रहा है \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: well have a model for the rest of language\n",
      "Actual Hindi Translation:  हमारे पास बाकि भषा के लिए मापद्न्ड होगा \n",
      "Predicted Hindi Translation:  तो हमारे पास अच्छी माँ का उपयोग हो सकता है \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T02:12:05.621335Z",
     "start_time": "2024-04-21T02:12:05.618580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_word(probs):\n",
    "  \"\"\"Samples a word from a probability distribution.\n",
    "\n",
    "  Args:\n",
    "    probs: A numpy array of probabilities for each word in the vocabulary.\n",
    "\n",
    "  Returns:\n",
    "    The index of the sampled word.\n",
    "  \"\"\"\n",
    "  # Sample a number from a uniform distribution between 0 and 1.\n",
    "  sample = np.random.rand()\n",
    "\n",
    "  # Accumulate probabilities until the sampled value is exceeded.\n",
    "  cumulative_prob = 0.0\n",
    "  for i, prob in enumerate(probs):\n",
    "    cumulative_prob += prob\n",
    "    if sample <= cumulative_prob:\n",
    "      return i\n",
    "\n",
    "  # If no word is selected due to rounding errors, return the last word.\n",
    "  return len(probs) - 1\n",
    "\n",
    "# Example usage:\n",
    "probs = np.array([0.2, 0.3, 0.4, 0.1])\n",
    "sampled_word_index = sample_word(probs)\n",
    "print(f\"Sampled word index: {sampled_word_index}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled word index: 0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
